{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Supervised Learning\n",
    "#### Regression vs Classification\n",
    "Repetition:\n",
    "Supervised learning problems can be sub-divided into regression and classification problems.\n",
    "\n",
    "**Regression** covers situations where **y is continuous/numerical**. \n",
    "- Predicting the value of the Dow in 6 months.\n",
    "- Predicting the price of a given house based on various inputs.\n",
    "\n",
    "**Classification** covers situations where **y is categorical**\n",
    "- Will the Dow be up (U) or down (D) in 6 months?\n",
    "- Is this email a SPAM or not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Regression\n",
    "- Linear regression is a simple approach to supervised learning\n",
    "- It assumes a linear dependence of Y on X1, X2, ... Xn\n",
    "- Linear Regression is very useful (conceptually and practically)\n",
    "\n",
    "![adv](../img/2/advertise.png)\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "Questions linear regression can help us to answer:\n",
    "1. Is there a relationship between advertising budget and sales? \n",
    "2. How strong is the relationship between advertising budget and sales? \n",
    "3. Which factors (media) contribute to sales?\n",
    "4. How accurately can we estimate the effect of each medium on sales? \n",
    "5. How accurately can we predict future sales?\n",
    "6. Is the relationship linear?\n",
    "7. Is there synergy among the advertising media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Simple Linear Regression\n",
    "Simple linear regression assumes there is a linear relationship between x and y.\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x $$\n",
    "\n",
    "![simple linear](../img/2/simple_linear_slope.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's gererate some random data for regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# generate random data from a line adding some noise\n",
    "def generate_regr(n_samples, x_mean, x_std, m, b, y_noise):\n",
    "    x, y = list(), list()\n",
    "    for i in range(n_samples):\n",
    "        x0 = random.gauss(x_mean, x_std)\n",
    "        y0 = m * x0 + b + (random.gauss(0, y_noise))\n",
    "        x.append(x0)\n",
    "        y.append(y0)\n",
    "    return np.array([x]).transpose(), y\n",
    "\n",
    "m, b, noise = 1, 0, 1\n",
    "X, y = generate_regr(50, 0, 10, m, b, noise)\n",
    "\n",
    "# plot dataset\n",
    "pyplot.close()\n",
    "pyplot.scatter(X,y)\n",
    "\n",
    "# ----------- create a model and fit it to the data ----------\n",
    "regr_model = LinearRegression()\n",
    "regr_model.fit(X, y)\n",
    "\n",
    "# regression line\n",
    "xl = np.linspace(min(X), max(X), 100)\n",
    "yl = regr_model.coef_[0] * xl + regr_model.intercept_\n",
    "yt= m * xl + b\n",
    "\n",
    "pyplot.plot(xl, yl, '-r', label='linear regression')\n",
    "pyplot.plot(xl, yt, '-b', label='truth ')\n",
    "pyplot.legend(loc='upper left')\n",
    "pyplot.show()\n",
    "\n",
    "print(\"slope:\")\n",
    "print(\"  true:\", m, \" model: \", regr_model.coef_[0])\n",
    "print(\"intercept:\")\n",
    "print(\"  true:\", b, \" model: \", regr_model.intercept_)\n",
    "\n",
    "print(\"R-squared: \", regr_model.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does this work?\n",
    "\n",
    "The optimization algorithm tries to find a line for which the **distance of the data points (residuals)** to this line is minimized. The way to *'punish'* this distance is called a **cost function**.\n",
    "\n",
    "![residuals](../img/2/residuals.png)\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "\n",
    "There are different **cost funtions** to pick from \n",
    "- RSS Residual sum of squares\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, because MSE \"punishes\" larger errors.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating Coefficients\n",
    "\n",
    "The algorithm goes through different combintions of the coefficients ($ \\beta_{0} ,  \\beta_{1}  $) and picks the one with the lowest cost.\n",
    "\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x $$\n",
    "\n",
    "![estimating coefficients](../img/2/coef_estimation.png)\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "![gradient decent](../img/2/gradient_decent.gif)\n",
    "source: [Towards Data Science](https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220)\n",
    "\n",
    "\n",
    "\n",
    "**Gradient Decent** is an algorithm that is used to *go down the slope* to find the minimal cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression attempts to model the relationship between **two or more explanatory variables** and a response variable by fitting a linear equation to observed data. \n",
    "\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x_{1} + \\beta_{2} x_{2} + ... +  \\beta_{n} x_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classification\n",
    "Logistic regression, SVM, Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Homework for tomorrow\n",
    "Think about a use case for machine learning in your department or domain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
