{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Supervised Learning\n",
    "#### Regression vs Classification\n",
    "Repetition:\n",
    "Supervised learning problems can be sub-divided into regression and classification problems.\n",
    "\n",
    "**Regression** covers situations where **y is continuous/numerical**. \n",
    "- Predicting the value of the Dow in 6 months.\n",
    "- Predicting the price of a given house based on various inputs.\n",
    "\n",
    "**Classification** covers situations where **y is categorical**\n",
    "- Will the Dow be up (U) or down (D) in 6 months?\n",
    "- Is this email a SPAM or not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Regression\n",
    "- Linear regression is a simple approach to supervised learning\n",
    "- Only **Simple Linear Regression** assumes a linear dependence of Y on $X_1, X_2, ... X_n$\n",
    "- Linear Regression is very useful (conceptually and practically)\n",
    "\n",
    "![adv](../img/2/advertise.png)\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "Questions linear regression can help us to answer:\n",
    "1. Is there a relationship between advertising budget and sales? \n",
    "2. How strong is the relationship between advertising budget and sales? \n",
    "3. Which factors (media) contribute to sales?\n",
    "4. How accurately can we estimate the effect of each medium on sales? \n",
    "5. How accurately can we predict future sales?\n",
    "6. Is the relationship linear?\n",
    "7. Is there synergy among the advertising media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Simple Linear Regression\n",
    "Simple linear regression assumes there is a linear relationship between x and y.\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x $$\n",
    "\n",
    "<img src=\"../img/2/simple_linear_slope.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's gererate some random data for regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope:\n",
      "  true: 10  model:  10.404072543829878\n",
      "intercept:\n",
      "  true: 0  model:  -1.904143604540662\n",
      "R-squared:  0.9478294569859264\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# generate random data from a line adding some noise\n",
    "def generate_regr(n_samples, x_mean, x_std, m, b, y_noise):\n",
    "    x, y = list(), list()\n",
    "    for i in range(n_samples):\n",
    "        x0 = random.gauss(x_mean, x_std)\n",
    "        y0 = m * x0 + b + (random.gauss(0, y_noise))\n",
    "        x.append(x0)\n",
    "        y.append(y0)\n",
    "    return np.array([x]).transpose(), y\n",
    "\n",
    "m, b, noise = 10, 0, 25\n",
    "X, y = generate_regr(50, 0, 10, m, b, noise)\n",
    "\n",
    "# plot dataset\n",
    "pyplot.close()\n",
    "pyplot.scatter(X,y)\n",
    "\n",
    "# ----------- create a model and fit it to the data ----------\n",
    "regr_model = LinearRegression()\n",
    "regr_model.fit(X, y)\n",
    "\n",
    "# regression line\n",
    "xl = np.linspace(min(X), max(X), 100)\n",
    "yl = regr_model.coef_[0] * xl + regr_model.intercept_\n",
    "yt= m * xl + b\n",
    "\n",
    "pyplot.plot(xl, yl, '-r', label='linear regression')\n",
    "pyplot.plot(xl, yt, '-b', label='truth ')\n",
    "pyplot.legend(loc='upper left')\n",
    "pyplot.show()\n",
    "\n",
    "print(\"slope:\")\n",
    "print(\"  true:\", m, \" model: \", regr_model.coef_[0])\n",
    "\n",
    "print(\"intercept:\")\n",
    "print(\"  true:\", b, \" model: \", regr_model.intercept_)\n",
    "\n",
    "print(\"R-squared: \", regr_model.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does this work?\n",
    "\n",
    "The optimization algorithm tries to find a line for which the **distance of the data points (residuals)** to this line is minimized. The way to *'punish'* this distance is called a **cost function**.\n",
    "\n",
    "![residuals](../img/2/residuals.png)\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "\n",
    "There are different **cost funtions** to pick from \n",
    "- RSS: Residual Sum of Squares\n",
    "$$  \\sum_i (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "- MAE: Mean Absolut Error\n",
    "$$ \\frac{1}{n} \\sum_i |y_i - \\hat{y}_i| $$\n",
    "is the easiest to understand, because it's the average error.\n",
    "\n",
    "\n",
    "- MSE: Mean Squared Error\n",
    "$$ \\frac{1}{n} \\sum_i (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "- RMSE Rooted MSE\n",
    "$$ \\sqrt{MSE}$$\n",
    "is even more popular than MSE, because RMSE is interpretable in the \"y\" units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating Coefficients\n",
    "\n",
    "The algorithm goes through different combintions of the coefficients ($ \\beta_{0} ,  \\beta_{1}  $) and picks the one with the lowest cost.\n",
    "\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x $$\n",
    "\n",
    "![estimating coefficients](../img/2/coef_estimation.png)\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "![gradient decent](../img/2/gradient_decent.gif)\n",
    "source: [Towards Data Science](https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220)\n",
    "\n",
    "\n",
    "\n",
    "**Gradient Decent** is an algorithm that is used to *go down the slope* to find the minimal cost.\n",
    "When using a quadratic cost function (RSS or MSE), we can be sure there is just a single minimum.\n",
    "\n",
    "\n",
    "Linear regression is called linear, not because we are fitting a line, but because with gradient decent we can linearly progress towards the minimal cost.\n",
    "\n",
    "**R-squared**: an unit-independant meassure of model quality\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\sum_i (\\hat{y}_i - y_i)^2}{\\sum_i (\\hat{y}_i - \\mu)^2}$$\n",
    "\n",
    "$R^2 $: The coefficient of determination, pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression attempts to model the relationship between **two or more explanatory variables** and a response variable by fitting a linear equation to observed data. \n",
    "\n",
    "$$ y = \\beta_{0}  + \\beta_{1} x_{1} + \\beta_{2} x_{2} + ... +  \\beta_{n} x_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By estimating coefficients, we can find out wich of the variables influence the outcome and how.\n",
    "\n",
    "![Multiple Linear Regression](../img/2/mult_lin_regr.png)\n",
    "\n",
    "\n",
    "Caution: Variables that have been found to be important when looked at in isolation, might not be important when examined in context.\n",
    "\n",
    "<img src=\"../img/2/simpl_mult_lin_regr_comp.png\" width=\"600\">\n",
    "\n",
    "Explanation: Newspaper and Radio advertisement are not independant, but correlated. Newspaper advertisement only seems to be effective, because of its correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classification\n",
    "\n",
    "- The **linear regression model** assumes that the response variable **Y is quantitative**.\n",
    "- But in many situations, the response variable is instead **qualitative or categorical**\n",
    "    - eye color ∈ {blue, brown, green}\n",
    "\t- email ∈ {ham, spam}\n",
    "- Predicting **qualitative responses** is known as **classification**. \n",
    "\n",
    "\n",
    "In this unit I will introduce three **classification methods**. \n",
    "- K-Nearest Neighbour, Logistic regression, Decision Trees, Suppor Vector Machines (SVMs)\n",
    "\n",
    "Later today you will  learn about others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Logistic regression\n",
    "Caution!!! The term \"Logistic Regression\" is a misnomer. It is NOT a regression algorithm, but a classification algorithm.\n",
    "![logistic regression](../img/2/logistic_regression.png)\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use:\n",
    "$$  p(x) = \\beta_{0}  + \\beta_{1} x $$\n",
    "\n",
    "    \n",
    "- Problems:\n",
    "    - negative probabilities \n",
    "    - not only values between 0 and 1\n",
    "\n",
    "- Using the **logistic function** can take care of that:\n",
    "$$  p(x) = \\frac{ e^{\\beta_{0}  + \\beta_{1} x }}{1 +  e^{\\beta_{0}  + \\beta_{1}x}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 K-Nearest Neighbours (KNN)\n",
    "K Nearest Neighbors is a flexible approach to estimate the Optimal Classifier.\n",
    "For any given X we find the k closest neighbors to X in the training data, and examine their corresponding Y.\n",
    "If the majority of the Y’s are orange we predict orange otherwise guess blue.\n",
    "The smaller that k is the more flexible the method will be.\n",
    "\n",
    "<img src=\"../img/2/optimal_classifier.png\" width=\"400\">\n",
    "A simulated data set consisting of 100 observations in each of two groups, indicated in blue and in orange. The purple dashed line represents the Bayes decision boundary. The orange background grid indicates the region in which a test observation will be assigned to the orange class, and the blue background grid indicates the region in which a test observation will be assigned to the blue class.  \n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k Nearest Neighbors is a flexible approach to estimate the Optimal Bayes Classifier.\n",
    "\n",
    "<img src=\"../img/2/knn_03.png\" width=\"500\">\n",
    "\n",
    "- For any given X we find the k closest neighbors to X in the training data, and examine their corresponding Y.\n",
    "- If the majority of the Y’s are orange we predict orange otherwise guess blue.\n",
    "- The smaller that k is the more flexible the method will be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../img/2/knn_10.png\" width=\"400\">\n",
    "\n",
    "\n",
    "The black curve indicates the KNN decision boundary on the data from above, using K = 10. \n",
    "The Bayes decision boundary is shown as a purple dashed line. The KNN and Bayes decision boundaries are very similar. \n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/2/knn_1_100.png\" width=\"500\">\n",
    "\n",
    "The smaller that k is the more flexible the method will be.\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/2/knn_train_test_error.png\" width=\"500\">\n",
    "\n",
    "- The **training error** rates keep going down as k decreases or equivalently as the flexibility increases.\n",
    "\n",
    "- However, the **test error rate** at first decreases but then starts to increase again. \n",
    "\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/2/complexity_train_test_error.png\" width=\"400\">\n",
    "\n",
    "- In general training errors will always decline.\n",
    "- However, test errors will decline at first (as reductions in bias dominate) but will then increase again (as increases in variance dominate).\n",
    "\n",
    "We must always keep this picture in mind when choosing a learning method. **More flexible/complicated is not always better!** \n",
    "\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example code\n",
    "from: https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 5\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "h = .08  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tree Based Methods involve *segmenting the predictor space* into a number of simple regions.\n",
    "- Since the set of splitting rules used to segment the predictor space can be summarized in a tree.\n",
    "- These types of approaches are known as **decision tree methods**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Based Methods can be used for both\n",
    "- regression\n",
    "- classification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for a regression tree\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img alt=\"baseball salary\" src=\"../img/2/decision_tree_baseball.png\" width=500></td>\n",
    "        <td><img alt=\"baseball salary\" src=\"../img/2/decision_tree_baseball_2.png\" width=200></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "In this example we try to predict the **salary** (colour coded (low: blue, green; high: yellow, red)) based on two features: \n",
    "number of **hits** and number of **years** of a player playing in the league.\n",
    "\n",
    "\n",
    "source: [ISLR](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Decision Trees\n",
    "- very **easy to explain** to people. (even easier to explain than linear regression)\n",
    "- more closely mirror human decision-making than do the regression and classification approaches. \n",
    "- can be **displayed graphically**, and are easily interpreted even by a non-expert. \n",
    "- can easily **handle qualitative predictors** without the need to create dummy variables. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantages of Decision Trees\n",
    "- Unfortunately, trees generally have **low level of predictive accuracy** compared to other regression and classification approaches. \n",
    "- Additionally, trees can be very **non-robust**. A small change in the data can cause a large change in the final estimated tree."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, by **aggregating many decision trees**, using methods like **bagging, random forests, and boosting**, the predictive performance of trees can be substantially improved. (next unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.2.4 Suppor Vector Machines (SVMs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soon to come\n"
     ]
    }
   ],
   "source": [
    "print(\"soon to come\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Exercise\n",
    "Think about a use case for machine learning in your department or domain:\n",
    "- What question do I want to answer? Typically something you do manually at the moment, or is handeled ineffectively.\n",
    "- What data set can I use to address the question?\n",
    "- Is this question really approachable by ML?\n",
    "- Is is unsupervised, supervised (regression, classification) ML?\n",
    "- What kind of algorithm would I suggest? (SVM, linear regression, clustering)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Learning Material \n",
    "- Data School Course (Kevin Markham): **Introduction to machine learning with scikit-learn** [Jupyter notebook 6](https://github.com/justmarkham/scikit-learn-videos) and [YouTube videos](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A)\n",
    "- Stanford University professors Trevor Hastie and Rob Tibshirani online course based on their textbook [free PDF](http://www-bcf.usc.edu/~gareth/ISL/), **An Introduction to Statistical Learning with Applications in R (ISLR)**. [ISLR course](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/)\n",
    "\n",
    "- MIT course on **Introduction to Computational Thinking and Data Science** ([lectures 9 and 10](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/lecture-videos/))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
