{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation\n",
    "In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived. The main purpose of using the testing data set is to test the generalization ability of a trained model ([Alpaydin 2010](http://scholar.google.com/scholar_lookup?title=Introduction%20to%20machine%20learning&author=E.%20Alpaydin&publication_year=2010)).\n",
    " \n",
    " In simpler terms, model evaluation tells you what kind of performance you can expect once your run **future** data through the model.\n",
    " \n",
    " The outline of the model building and evaluation process is given below.\n",
    " <img src=\"../img/4/model_evaluation_process.PNG\" width=400>\n",
    " \n",
    " We will start by training a classification model that uses the [scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) of the [Random Forest](https://en.wikipedia.org/wiki/Random_forest) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Building a classifier model using the Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, TimeSeriesSplit\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# data are stored here\n",
    "data_folder = '../datasets'\n",
    "\n",
    "# integer for the random seed\n",
    "THE_ANSWER = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint contains the following features:\n",
      "\n",
      "[ 0.6156176  -0.78584207  0.56566955  0.60753437 -0.17992427 -0.32535287\n",
      " -0.32719857 -0.32719857 -0.15201037  0.18929607  0.21877548         nan\n",
      " -1.564559           nan  1.87409565  0.3909332  -1.64262716 -0.33748312\n",
      "  1.64262716         nan         nan  0.90230299         nan         nan\n",
      "  1.37062409 -0.00604467 -0.01317495 -0.76401196  0.93544524 -0.04058151\n",
      " -0.17166864 -0.02962516 -0.26744559] \n",
      "\n",
      "Each data point is described by 33 features.\n",
      "The number of data points in the training dataset is 65579.\n"
     ]
    }
   ],
   "source": [
    "# load all data\n",
    "data = np.load('%s/data.npz' % data_folder)\n",
    "\n",
    "# extract training data\n",
    "# (strategies for splitting data into training and test sets are detailed in Section 4.4)\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "\n",
    "#Let's have a look at the first datapoint\n",
    "print(\"The first datapoint contains the following features:\\n\")\n",
    "print(X_train[0], '\\n')\n",
    "print(\"Each data point is described by %d features.\" % X_train.shape[1])\n",
    "print(\"The number of data points in the training dataset is %d.\" % X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n",
      "The class == 1 objects make 34% of the training set.\n"
     ]
    }
   ],
   "source": [
    "# let's take a look at the class labels stored in the y_train array\n",
    "print(y_train)\n",
    "print('The class == 1 objects make %0.f%% of the training set.' % (100*y_train.sum()/y_train.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**only 34% of objects are of class 1 --> the data set is imbalanced**\n",
    "\n",
    "Let's start with training a classifier on the training set and then testing its performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# print out the default values of model hyper-parameters (will talk about hyper-parameters later)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the number of trees to 500, and the random seed to THE_ANSWER for reproducibility\n",
    "model.set_params(n_estimators=500, random_state=THE_ANSWER)\n",
    "#model = RandomForestClassifier(n_estimators=500, random_state=THE_ANSWER) # another way of doing it\n",
    "\n",
    "# check that the model changed\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values in the training set are NaN (i.e., are missing).\n",
    "# The Random Forest classifier does not like that, so we set NaN values to 10000.\n",
    "X_train_fixed = X_train.copy()\n",
    "X_train_fixed[np.isnan(X_train_fixed)] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using training data\n",
    "model.fit(X_train_fixed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating a model using classification metrics\n",
    "\n",
    "Now that we have fit a model, we need to evaluate its performance on a test set. Strategies for splitting data into training and test sets are detailed in [Section 4.4](#4_4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class:      [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "Predicted class: [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# first, extract test data\n",
    "X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "# if there are NaNs in the test set, set them to 10000.\n",
    "X_test_fixed = X_test.copy()\n",
    "X_test_fixed[np.isnan(X_test)] = 10000\n",
    "\n",
    "# sanity check: only 35% of objects are of class 1 --> the test set is also imbalanced\n",
    "#print('The class == 1 objects make %0.f%% of the test set.\\n' % (100*y_test.sum()/y_test.size))\n",
    "\n",
    "# now push the test set through the model to get the predicted classes\n",
    "y_pred = model.predict(X_test_fixed)\n",
    "\n",
    "print('True class:     ', y_test[0:20])\n",
    "print('Predicted class:', y_pred[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Confusion matrix\n",
    "When performing classification predictions, there are four types of outcomes that could occur.\n",
    "\n",
    "#### True positives\n",
    "are when you predict an observation belongs to a class and it actually does belong to that class.\n",
    "#### True negatives\n",
    "are when you predict an observation does not belong to a class and it actually does not belong to that class.\n",
    "#### False positives\n",
    "occur when you predict an observation belongs to a class when in reality it does not.\n",
    "#### False negatives\n",
    "occur when you predict an observation does not belong to a class when in fact it does.\n",
    "\n",
    "These four outcomes are often plotted on a confusion matrix. Let's plot the confusion matrix for the predictions we have obtained above on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad900d46a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [1, 0]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt=' ', cmap=\"Blues\"); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "#ax.xaxis.set_ticklabels([1, 0]); ax.yaxis.set_ticklabels([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  Positives = 6469\n",
      "True  Negatives = 13194\n",
      "False Positives = 1031\n",
      "False Negatives = 1340\n"
     ]
    }
   ],
   "source": [
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "\n",
    "print(\"True  Positives = %i\" % TP)\n",
    "print(\"True  Negatives = %i\" % TN)\n",
    "print(\"False Positives = %i\" % FP)\n",
    "print(\"False Negatives = %i\" % FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these numbers, we can now calculate some classification metrics, such as accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Accuracy\n",
    "\n",
    "Accuracy is defined as the percentage of correct predictions for the test data.\n",
    "\n",
    "$$accuracy = \\frac{{\\rm number\\, of\\, correct\\, predictions}}{{\\rm number\\, of\\, all\\, predictions}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.892.\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy\n",
    "print('The accuracy is %.3f.' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a great result, right? Maybe not since we have an imbalanced data set (i.e., class == 1 objects make only 35% of the test set). Here's an extreme example how accuracy can be misleading when the classes are imbalanced:\n",
    "\n",
    "Imagine a data set where 90% of objects are of class 0. A naive classifier that predicts 0 for all objects will have an accuracy of 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Precision and Recall<a name=\"4_2_3\"></a>\n",
    "\n",
    "In my opinion, what most business people would like to know is the following:\n",
    "1. What is the detection rate? Did we correctly identify 50%, 80%, or more of all class 1 objects (e.g., instructions that will fail to settle)?\n",
    "2. What is the false alarm rate? What percentage of those tagged as class 1 are **not** of class 1?\n",
    "\n",
    "The detection rate is called [\"recall\"](https://en.wikipedia.org/wiki/Precision_and_recall) in machine learning, and the false alarm rate is related to [\"precision\"](https://en.wikipedia.org/wiki/Precision_and_recall) (actually, it is 1-precision).\n",
    "\n",
    "#### Precision\n",
    "is defined as the fraction of relevant examples (true positives) among all of the examples which were predicted to belong in a certain class.\n",
    "$$Precision = \\frac{true\\, positives}{true\\, positives+false\\, positives}$$\n",
    "\n",
    "#### Recall\n",
    "is defined as the fraction of examples which were predicted to belong to a class with respect to all of the examples that truly belong in the class.\n",
    "$$Recall = \\frac{true\\, positives}{true\\, positives+false\\, negatives}$$\n",
    "\n",
    "![image](../img/4/img7.png)\n",
    "\n",
    "[Source](https://www.jeremyjordan.me/evaluating-a-machine-learning-model/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate precision and recall using the predictions we have obtained above on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision obtained on the test set is 86% and recall is 83%.\n"
     ]
    }
   ],
   "source": [
    "p = precision_score(y_test, y_pred)\n",
    "r = recall_score(y_test, y_pred)\n",
    "print('The precision obtained on the test set is %.0f%% and recall is %.0f%%.' % (p*100, r*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above precision and recall indicate that our model is able to detect 83% of all class == 1 objects (e.g., failed settlements), while having a false alarm rate of only 14% (remember that the false alarm rate = 1 - precision).\n",
    "\n",
    "But what if a detection rate of 86% is not good enough for your use case? What if you willing to accept a higher false alarm rate if that would enable you to identify more of class == 1 objects (i.e., have a higher detection rate)?\n",
    "\n",
    "This can be achieved by:\n",
    "1. Calculating classification **scores** (values 0 *to* 1) instead of predicting class **labels** (values 0 *or* 1),\n",
    "2. Plotting the precision-recall curve, and\n",
    "3. Selecting all objects that have the classification score higher than some threshold.\n",
    "\n",
    "Let's start by calculating and explaining classification scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88866667 0.11133333]\n",
      " [0.828      0.172     ]\n",
      " [0.85693333 0.14306667]\n",
      " [0.88866667 0.11133333]\n",
      " [0.80310476 0.19689524]]\n",
      "The y_scores is a 2-dimensional array: (22034, 2)\n"
     ]
    }
   ],
   "source": [
    "# push the test data set through the model to get the classification *scores* (not labels)\n",
    "# (note that we use the \"predict_proba\" method and not \"predict\")\n",
    "y_scores = model.predict_proba(X_test_fixed)\n",
    "\n",
    "# the model calculates the score for both classes (0 and 1). Each row sums to 1.\n",
    "print(y_scores[0:5, :])\n",
    "print('The y_scores is a 2-dimensional array:', y_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have classification scores, let's plot the (1-precision) vs. recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score > 0.557:  78% detection rate at 10% false alarm rate.\n",
      "Score > 0.487:  84% detection rate at 15% false alarm rate.\n",
      "Score > 0.451:  87% detection rate at 20% false alarm rate.\n",
      "Score > 0.000: 100% detection rate at 65% false alarm rate (naive approach).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad9013f160>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the detection rate vs. false alarm rate\n",
    "p, r, thresh = precision_recall_curve(y_test, y_scores[:, 1])\n",
    "thresh = np.append(0, thresh)\n",
    "print('Score > %.3f:  %.0f%% detection rate at 10%% false alarm rate.' % (thresh[(1-p) > 0.1][-1], 100*r[(1-p) > 0.1][-1]))\n",
    "print('Score > %.3f:  %.0f%% detection rate at 15%% false alarm rate.' % (thresh[(1-p) > 0.15][-1], 100*r[(1-p) > 0.15][-1]))\n",
    "print('Score > %.3f:  %.0f%% detection rate at 20%% false alarm rate.' % (thresh[(1-p) > 0.2][-1], 100*r[(1-p) > 0.2][-1]))\n",
    "print('Score > 0.000: 100%% detection rate at %.0f%% false alarm rate (naive approach).' % (100-100*y_test.sum()/y_test.size))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.step((1-p)*100, r*100, color='b', where='post', label='late settlements')\n",
    "ax.set_xlabel('False alarm rate [%]')\n",
    "ax.set_ylabel('Detection rate [%]')\n",
    "ax.set_ylim([0.0, 101])\n",
    "_ = ax.set_xlim([0.0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</a>Thus, if we select all objects (rows) that have the classification score (y_scores[:, 1]) greater than 0.557, we can expect a sample where 78% of objects will be of class 1 (e.g., will be failed settlements), and only 10% will be of class 0.\n",
    "\n",
    "Example: Let's say there are 100 objects (rows) that have the classification score greater than 0.577. This mean that 90 objects will truly be of class 1 (false alarm rate is 10% --> precision is 90% --> 100*0.9 = 90). The total number of class 1 objects is 115 ( = 90/0.78 --> because detection rate is 78%), which means the algorithm misses 25 objects (rows) of class 1.\n",
    "\n",
    "The area under the precision-recall curve (AUPRC) is also a [metric](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html). The perfect classifier (model) has a detection rate of 100% and false alarm rate of 0%, and the AUPRC = 1.\n",
    "\n",
    "What is the AUPRC for the model we trained above? Let's calculate it using the test data set.<a name=\"precision_recal_sec_end\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the precision-recall curve is 0.923.\n"
     ]
    }
   ],
   "source": [
    "# calculate the area under the precision-recall curve for class == 1 objects\n",
    "# by feeding the true class label (y_test) and the predicted classification scores (y_scores[:, 1])\n",
    "print('The area under the precision-recall curve is %.3f.' % average_precision_score(y_test, y_scores[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Log loss or cross-entropy\n",
    "\n",
    "The metric of choice for evaluating multi-class classification models. For more details, see [here](http://wiki.fast.ai/index.php/Log_Loss) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Regression metrics\n",
    "\n",
    "**(Root) Mean Squared Error** is simply defined as the (root of the) average of squared differences between the predicted output and the true output. A smaller value of this metric indicates a better model. The root of MSE is in units of *y*.\n",
    "$$MSE(y_{true}, y_{pred})=\\frac{1}{n_{samples}}\\sum{(y_{true} - y_{pred})^2}$$\n",
    "\n",
    "[${\\bf R^2}$ **coefficient**](https://en.wikipedia.org/wiki/Coefficient_of_determination) or the **coefficient of determination** represents the proportion of variance in the outcome that our model is capable of predicting based on its features. The values range from 1 (perfect model) to minus infinity (the model can be infinitely bad).\n",
    "$$R^2(y_{true}, y_{pred}) = 1 - \\frac{\\sum{(y_{true} - y_{pred})^2}}{\\sum{(y_{true} - \\bar{y})^2}}; \\bar{y} = \\frac{1}{n_{samples}}\\sum{y_{true}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Strategies for splitting data into training, validation, and test sets<a name=\"4_4\"></a>\n",
    "\n",
    "### 4.4.1 Hold-out validation\n",
    "<img src=\"../img/4/hold-out_validation2.PNG\" width=400>\n",
    "\n",
    "The simplest splitting strategy. A good choice when you have a lot of data. The **only** choice when you have time-dependent data. I use 60%-20%-20% when splitting data into training, validation, and test sets.\n",
    "\n",
    "*Shuffle* randomizes the order of rows before splitting. Do this is if your data set does **not** depend on time.\n",
    "\n",
    "*Stratify* makes sure the ratio of classes is the same after splitting (stratify, thus, makes no sense for regressions). If building a classification model, always do this (I cannot think of situations when not to do it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train-valid-test split is 60%-20%-20%.\n",
      "The ratios of classes in train, valid, and test sets are 0.34, 0.35, and 0.35.\n"
     ]
    }
   ],
   "source": [
    "# create a large data set, and split it\n",
    "X, y = np.concatenate([data['X_devel'], data['X_test']]), np.concatenate([data['y_devel'], data['y_test']])\n",
    "\n",
    "# do a 80-20 stratified shuffle split to create a development and a test set\n",
    "X_devel2, X_test2, y_devel2, y_test2 = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=THE_ANSWER)\n",
    "\n",
    "# now split the development set into a train and validation sets (stratify and shuffle)\n",
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_devel2, y_devel2, test_size=0.25, random_state=THE_ANSWER)\n",
    "\n",
    "# make sure we got the right ratios\n",
    "print('The train-valid-test split is %.0f%%-%.0f%%-%.0f%%.' % (100*y_train2.size/float(y.size), 100*y_valid2.size/float(y.size), 100*y_test2.size/float(y.size)))\n",
    "\n",
    "print('The ratios of classes in train, valid, and test sets are %.2f, %.2f, and %.2f.' % (y_train2.sum()/float(y_train2.size),\n",
    "                                                                                          y_valid2.sum()/float(y_valid2.size),\n",
    "                                                                                          y_test2.sum()/float(y_test2.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 k-fold cross-validation\n",
    "<img src=\"../img/4/k-fold_cross-validation.PNG\" width=600>[ISLR](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "A more complicated splitting strategy. The input data set is optionally shuffled and then split into *k* equal-sized non-overlapping groups (with the same ratio of classes, if stratified splitting is used). Each of these groups acts as a validation set (shown in beige), and the remainder as a training set (shown in blue). The test error is estimated by averaging the five resulting scoring estimates (e.g., area under the precision-recall curve).\n",
    "\n",
    "Recommended usage: 5 to 10 folds, shuffle (use a fixed seed for reproducibility), and stratify (if building a classification model).\n",
    "\n",
    "Example: Use the above-defined Random Forest classification model, and measure it's performance using 5-fold shuffled and stratified cross-validation on the *X_train_fixed* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score is 0.9910, and the rms scatter is 0.0004\n"
     ]
    }
   ],
   "source": [
    "# measure average AUPRC using 5-fold shuffled and stratified cross-validation\n",
    "#cv_scores = cross_val_score(model, X_train_fixed, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=THE_ANSWER), n_jobs=1, scoring='average_precision')\n",
    "#print('Average CV score is %.4f, and the rms scatter is %.4f' % (np.average(cv_scores), np.std(cv_scores, ddof=1)))\n",
    "print('Average CV score is %.4f, and the rms scatter is %.4f' % (0.9910, 0.0004))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Why shuffling and cross-validation are very, very bad when using time-dependent data (e.g., financial data)\n",
    "\n",
    "In [Section 4.2.3](#4_2_3), we trained a Random Forest classifier on a training set (*X_train_fixed*), and evaluated the model on the test set (*X_test_fixed*) using the area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the precision-recall curve is 0.923.\n"
     ]
    }
   ],
   "source": [
    "# calculate the area under the precision-recall curve for class == 1 objects\n",
    "# by feeding the true class label (y_test) and the predicted classification scores (y_scores[:, 1])\n",
    "print('The area under the precision-recall curve is %.3f.' % average_precision_score(y_test, y_scores[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the \n",
    "X_valid, y_valid = data['X_valid'], data['y_valid']\n",
    "X_devel, y_devel = data['X_devel'], data['y_devel']\n",
    "X_test, y_test = data['X_test'], data['y_test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
